{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network for recognizing handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recognition of handwritten digits with the nmist dataset (http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits) can be seen as the hello world example of neural networks. In this notebook you will implement a neural network with convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data and visualize some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint   \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "numpy.random.seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data and make a training and testing split\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshaping to a format suitable to keras (batch, height, width, channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')\n",
    "\n",
    "# Normalize the input features\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "\n",
    "# Encode the classes to numbers (one-hot encode)\n",
    "number_of_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "y_test = np_utils.to_categorical(y_test, number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize some of our training data\n",
    "plt.figure(figsize=(12, 3))\n",
    "x, y = 10, 4\n",
    "for i in range(20):  \n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('Label: %s' % int(sum(y_train[i] * [0,1,2,3,4,5,6,7,8,9])))\n",
    "    plt.imshow(X_train[i].reshape((28,28)), cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each vector in our dataset is representing a grayscale image of 28 to 28 pixels. Every value in a vector represents a grayscale value of a single pixel (0-255 normalized to 0-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize composition of an image\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(X_train[0].reshape((28,28)), cmap='gray')\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        color = 'white' if X_train[0][j,i] < .4 else 'black' \n",
    "        plt.annotate('{:.1f}'.format(float(X_train[0][j,i])), (i-.3, j+.2), color=color, size=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Build a convolutional neural network for training the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: You have to define the architecture of the layers. You will need convolutional layers (https://keras.io/layers/convolutional/#conv2d) to handle spatial information of the pixels. Some hints are:\n",
    "* Stick with the sequential model (there is no temporal information here)\n",
    "* It is advised to follow a convolutional layer (Conv2D) by a pooling layer (MaxPooling2D)\n",
    "* If your accuracy is good but your validation accuracy is not, try to prevent overfitting by adding a dropout layer (https://keras.io/layers/core/#dropout)\n",
    "* To rectifier unit has proven to be a good start for the activation of layers in neural networks (https://keras.io/activations/#available-activations)\n",
    "* Because you try to predict multiple classes, the final layer needs to be a dense layer with the same amout of neurons as classes to predict. Then use a softmax activation function (http://dataaspirant.com/2017/03/07/difference-between-softmax-function-and-sigmoid-function/) to predict the final class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our convolutional neural network\n",
    "model = Sequential()\n",
    "# TODO: Add the necessary layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: If you have built your model you can compile, fit and validate it with the next cell. If the model is learning to slow you need to reduce the number of parameters (e.g. layers). Try to experiment with the parameters *epochs* and *batch_size*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "# Fit the model\n",
    "# TODO: Experiment with the parameters epochs and patch_size\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "          callbacks = [checkpointer], epochs=5, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you made use of convolutional layers, added proper pooling and some dropout it should be relatively easy to achieve an accuracy of > 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "model.load_weights('mnist.model.weights.best.hdf5')\n",
    "metrics = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(\"Metrics (loss & accuracy): %s\" % metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions with the trained model\n",
    "y_predicted = model.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "x, y = 10, 4\n",
    "for i in range(20):  \n",
    "    plt.subplot(2, 10, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title('Pred: %s' % int(sum(y_predicted[i] * [0,1,2,3,4,5,6,7,8,9])))\n",
    "    plt.imshow(X_test[i].reshape((28,28)), cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Congratulation, you just implemented a convolutional neural network! Now move on the next exercise with color images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
