{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Learning boolean operations with neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np \n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define logical or (only for training!)\n",
    "def logical_or(values):\n",
    "    if values[0] == 1 or values[1] == 1:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate some training data\n",
    "X = [[random.randint(0,1), random.randint(0,1)] for x in range(1000)]\n",
    "y = [logical_or(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vectors (X): [[0, 0], [0, 1], [1, 1], [1, 0], [1, 1]]\n",
      "Target variable (y): [0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Print our input and output data\n",
    "print('Input vectors (X): %s' % X[:5])\n",
    "print('Target variable (y): %s' % y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining our trivial network with a single layer, a tanh activation function and a bias unit\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(2,), activation='tanh', use_bias=True))\n",
    "model.compile(optimizer=\"SGD\", loss=\"mean_squared_error\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 189us/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 64us/step - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 67us/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 66us/step - loss: 0.0077 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f03c529d940>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training our model with the generated training data\n",
    "model.fit(np.array(X), np.array(y), epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.88151067],\n",
       "       [ 0.99109834],\n",
       "       [ 0.04673347],\n",
       "       [ 0.87854779]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our model with some validation data\n",
    "model.predict(np.array([[1,0],[1,1],[0,0],[0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.33573616],\n",
      "       [ 1.32259905]], dtype=float32), array([ 0.04676754], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Visualize the weights of the model\n",
    "for layer in model.layers:\n",
    "    print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We define logical and (only for training!)\n",
    "def logical_and(values):\n",
    "    if values[0] == 1 and values[1] == 1:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate some training data\n",
    "X = [[random.randint(0,1), random.randint(0,1)] for x in range(1000)]\n",
    "y = [logical_and(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vectors (X): [[0, 0], [0, 1], [1, 0], [1, 0], [1, 1]]\n",
      "Target variable (y): [0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Print our input and output data\n",
    "print('Input vectors (X): %s' % X[:5])\n",
    "print('Target variable (y): %s' % y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining our trivial network with a single layer, a tanh activation function and a bias unit\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(2,), activation='tanh', use_bias=True))\n",
    "model.compile(optimizer=\"SGD\", loss=\"mean_squared_error\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 0s 239us/step - loss: 0.2229 - acc: 0.5060\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.1741 - acc: 0.7340\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.1377 - acc: 0.7850\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.1147 - acc: 0.7850\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.1016 - acc: 0.8660: 0s - loss: 0.1039 - acc: 0.838\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0951 - acc: 1.0000\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0913 - acc: 1.0000\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0888 - acc: 1.0000\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0870 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0855 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0844 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0835 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0826 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0819 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 0s 71us/step - loss: 0.0814 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0809 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0805 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 0s 83us/step - loss: 0.0801 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 0.0799 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0796 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0794 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0792 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 0s 87us/step - loss: 0.0791 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0790 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0789 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0788 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0787 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 0s 82us/step - loss: 0.0786 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0786 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0785 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0785 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0785 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.0785 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.0784 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0784 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0784 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 0s 70us/step - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 0s 69us/step - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0784 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 0s 81us/step - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 0s 74us/step - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 0s 77us/step - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 0s 76us/step - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 0s 75us/step - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 0s 80us/step - loss: 0.0783 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 0s 73us/step - loss: 0.0783 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f03c0221e10>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training our model with the generated training data\n",
    "model.fit(np.array(X), np.array(y), epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28036863],\n",
       "       [ 0.63472402],\n",
       "       [-0.24683933],\n",
       "       [ 0.20616394]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our model with some validation data\n",
    "model.predict(np.array([[1,0],[1,1],[0,0],[0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.54012638],\n",
      "       [ 0.46120593]], dtype=float32), array([-0.25204426], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Visualize the weights of the model\n",
    "for layer in model.layers:\n",
    "    print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Implement XNOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We define logical xnor (only for training!)\n",
    "def logical_xnor(values):\n",
    "    if values[0] == 1 and values[1] == 1:\n",
    "        return 1\n",
    "    if values[0] == 0 and values[1] == 0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate some training data\n",
    "X = [[random.randint(0,1), random.randint(0,1)] for x in range(1000)]\n",
    "y = [logical_xnor(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thats what xnor is\n",
    "[logical_xnor(x) for x in [[1,0],[1,1],[0,0],[0,1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining our trivial network with a single layer, a tanh activation function and a bias unit\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_shape=(2,), activation='tanh', use_bias=True))\n",
    "model.add(Dense(1, activation='tanh', use_bias=True))\n",
    "model.compile(optimizer=\"SGD\", loss=\"mean_squared_error\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 1s 568us/step - loss: 0.3342 - acc: 0.4900\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 0s 254us/step - loss: 0.2509 - acc: 0.4970\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 0s 240us/step - loss: 0.2488 - acc: 0.5730\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 0s 239us/step - loss: 0.2486 - acc: 0.5150\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 0s 253us/step - loss: 0.2480 - acc: 0.6270\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 0s 257us/step - loss: 0.2473 - acc: 0.5680\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 0s 235us/step - loss: 0.2470 - acc: 0.6170\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 0s 240us/step - loss: 0.2463 - acc: 0.6870\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 0s 249us/step - loss: 0.2456 - acc: 0.7290\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 0s 252us/step - loss: 0.2449 - acc: 0.7080\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 0s 255us/step - loss: 0.2441 - acc: 0.7240\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 0s 244us/step - loss: 0.2426 - acc: 0.6660\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 0s 237us/step - loss: 0.2418 - acc: 0.7480\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 0s 249us/step - loss: 0.2403 - acc: 0.7190\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 0s 241us/step - loss: 0.2387 - acc: 0.7480\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 0s 253us/step - loss: 0.2370 - acc: 0.7480\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 0s 242us/step - loss: 0.2350 - acc: 0.7480\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 0s 222us/step - loss: 0.2329 - acc: 0.7480\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 0s 236us/step - loss: 0.2304 - acc: 0.7480\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 0s 240us/step - loss: 0.2278 - acc: 0.7480\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 0s 233us/step - loss: 0.2250 - acc: 0.7480\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 0s 225us/step - loss: 0.2222 - acc: 0.7480\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 0s 229us/step - loss: 0.2193 - acc: 0.7480\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 0s 235us/step - loss: 0.2162 - acc: 0.7480\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 0s 244us/step - loss: 0.2132 - acc: 0.7480\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 0s 236us/step - loss: 0.2102 - acc: 0.7480\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 0s 240us/step - loss: 0.2070 - acc: 0.7480\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 0s 262us/step - loss: 0.2040 - acc: 0.7480\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 0s 241us/step - loss: 0.2006 - acc: 0.7480\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 0s 245us/step - loss: 0.1979 - acc: 0.7480\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 0s 232us/step - loss: 0.1949 - acc: 0.7480\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 0s 244us/step - loss: 0.1918 - acc: 0.7480\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 0s 254us/step - loss: 0.1890 - acc: 0.7480\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 0s 252us/step - loss: 0.1861 - acc: 0.7480\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 0s 238us/step - loss: 0.1831 - acc: 0.7480\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 0s 244us/step - loss: 0.1800 - acc: 0.7480\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 0s 235us/step - loss: 0.1767 - acc: 0.7480\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 0s 236us/step - loss: 0.1731 - acc: 0.7480\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 0s 222us/step - loss: 0.1693 - acc: 0.7480\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 0s 227us/step - loss: 0.1650 - acc: 0.7480\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 0s 227us/step - loss: 0.1597 - acc: 0.7480\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 0s 225us/step - loss: 0.1533 - acc: 0.7480\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 0s 229us/step - loss: 0.1453 - acc: 0.7480\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 0s 231us/step - loss: 0.1358 - acc: 0.8840\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 0s 234us/step - loss: 0.1247 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 0s 232us/step - loss: 0.1123 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 0s 236us/step - loss: 0.0996 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 0s 224us/step - loss: 0.0871 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 0s 232us/step - loss: 0.0753 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 0s 227us/step - loss: 0.0647 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 0s 223us/step - loss: 0.0553 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 0s 223us/step - loss: 0.0472 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 0s 220us/step - loss: 0.0402 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 0s 225us/step - loss: 0.0344 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 0s 223us/step - loss: 0.0296 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 0s 217us/step - loss: 0.0256 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 0s 237us/step - loss: 0.0223 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 0s 243us/step - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 0s 242us/step - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 0s 239us/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 0s 236us/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 0s 242us/step - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 0s 242us/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 0s 239us/step - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 0s 241us/step - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 0s 247us/step - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 0s 260us/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 0s 245us/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 0s 234us/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 0s 251us/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 0s 242us/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 0s 252us/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 0s 237us/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 0s 244us/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 0s 240us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 0s 243us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 0s 253us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 0s 253us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 0s 272us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 0s 239us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 0s 231us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 230us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 0s 223us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 0s 243us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 0s 256us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 0s 245us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 0s 230us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 0s 236us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 0s 257us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 0s 245us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 0s 239us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 0s 241us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 0s 238us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 0s 243us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 0s 240us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 0s 269us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 0s 241us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 0s 243us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 0s 238us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 0s 246us/step - loss: 0.0019 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0356c8c208>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training our model with the generated training data\n",
    "model.fit(np.array(X), np.array(y), epochs=100, verbose=1, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0085232 ],\n",
       "       [ 0.94722325],\n",
       "       [ 0.9309516 ],\n",
       "       [ 0.00631127]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our model with some validation data\n",
    "model.predict(np.array([[1,0],[1,1],[0,0],[0,1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Exercise: Implement XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We define logical xor (only for training!)\n",
    "def logical_xor(values):\n",
    "    if values[0] == 0 and values[1] == 1:\n",
    "        return 1\n",
    "    if values[0] == 1 and values[1] == 0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate some training data\n",
    "X = [[random.randint(0,1), random.randint(0,1)] for x in range(1000)]\n",
    "y = [logical_xor(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vectors (X): [[1, 1], [1, 1], [1, 0], [1, 1], [0, 0], [1, 0], [1, 1], [0, 1]]\n",
      "Target variable (y): [0, 0, 1, 0, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Print our input and output data\n",
    "print('Input vectors (X): %s' % X[:8])\n",
    "print('Target variable (y): %s' % y[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create testing and validation split\n",
    "X_train = X[:500]\n",
    "y_train = y[:500]\n",
    "X_validation = X[500:]\n",
    "y_validation = y[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining our trivial network with a single layer, a tanh activation function and a bias unit\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_shape=(2,), activation='tanh', use_bias=True))\n",
    "model.add(Dense(1, activation='tanh', use_bias=True))\n",
    "model.compile(optimizer=\"Adam\", loss=\"mean_squared_error\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAE1CAYAAAD6akEFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nStRgiYiIiIiIRMn/AxKZqZGlTFhXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0333ea1208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f03336453c8>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "import livelossplot as lp\n",
    "\n",
    "plot_learning = lp.PlotLossesKeras()\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='xor.model.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "callbacks = [checkpointer, plot_learning]\n",
    "\n",
    "# Training our model with the generated training data\n",
    "model.fit(np.array(X), np.array(y), validation_data=(np.array(X_validation), np.array(y_validation)), \n",
    "          callbacks = callbacks, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.71922016],\n",
       "       [ 0.10948835],\n",
       "       [ 0.10252257],\n",
       "       [ 0.64064586]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the weights that yielded the best validation accuracy\n",
    "model.load_weights('xor.model.weights.best.hdf5')\n",
    "\n",
    "# Evaluate our model with some validation data\n",
    "model.predict(np.array([[1,0],[1,1],[0,0],[0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 93us/step\n",
      "\n",
      " Model Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "X_test = [[random.randint(0,1), random.randint(0,1)] for x in range(50)]\n",
    "y_test = [logical_xor(x) for x in X_test]\n",
    "score = model.evaluate(np.array(X_test), np.array(y_test), verbose=1)\n",
    "print('\\n', 'Model Accuracy: %.3f' % score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
