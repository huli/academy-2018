{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification with a convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is using the cifar10 dataset of keras (https://keras.io/datasets/). The dataset provides 50k training and 10k testing images of a small size and low resolution suitable for low performance environments. The images are in color and there are 10 target classes. The objective is to correctly predict as many images as possible with an convolutional neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the cifar10 dataset and explore the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the preshuffled train and test data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some images and their labels (source: https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "cifar10_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "for i in range(36):\n",
    "    ax = fig.add_subplot(3, 12, i + 1, xticks=[], yticks=[])\n",
    "    ax.set_title(\"%s\" % cifar10_labels[y_train[i][0]])\n",
    "    ax.imshow(np.squeeze(x_train[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every image consists of a 3-dimensional vector with the shape (32,32,3). The first two dimensions are corresponding to width and height of the image while the third dimension is holding the values of the three color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the individual channels of a sample\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 10))\n",
    "axes[0].imshow(x_train[2])\n",
    "axes[0].set_title('Original (RGB)\\n%s' % str(x_train[2].shape))\n",
    "\n",
    "for i, l in zip(range(3), ['Red channel','Green channel','Blue channel']): \n",
    "    channel=np.zeros((32,32,3))\n",
    "    channel[:,:,i] = x_train[2][:,:,i]\n",
    "    axes[i+1].imshow(channel)\n",
    "    axes[i+1].set_title('%s\\n(32, 32, 1)' % (l))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the three color values from 0-255 to 0-1\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels into categorical values (one-hot encoding)\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Break training set into training and validation sets\n",
    "(x_train, x_valid) = x_train[5000:], x_train[:5000]\n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "# Print shape of training set\n",
    "print('x_train shape:', x_train.shape)\n",
    "\n",
    "# print number of training, validation, and test images\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(x_valid.shape[0], 'validation samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Define the architecture for the convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: \n",
    "*(Nothing new if you solved the mnist exercise)* You have to define the architecture of the layers. You will need convolutional layers (https://keras.io/layers/convolutional/#conv2d) to handle spatial information of the pixels. Some hints are:\n",
    "* Stick with the sequential model (there is no temporal information here)\n",
    "* It is advised to follow a convolutional layer (Conv2D) by a pooling layer (MaxPooling2D)\n",
    "* If your accuracy is good but your validation accuracy is not, try to prevent overfitting by adding a dropout layer (https://keras.io/layers/core/#dropout)\n",
    "* To rectifier unit has proven to be a good start for the activation of layers in neural networks (https://keras.io/activations/#available-activations)\n",
    "* Because you try to predict multiple classes, the final layer needs to be a dense layer with the same amout of neurons as classes to predict. Then use a softmax activation function (http://dataaspirant.com/2017/03/07/difference-between-softmax-function-and-sigmoid-function/) to predict the final class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the architecture for the neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "# TODO: Add the necessary layers\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of the model to examine parameters to train\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: The 'Trainable params' shows you the number of parameters the network will have to train. The more parameters, the slower the network learns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "import livelossplot as lp\n",
    "\n",
    "plot_learning = lp.PlotLossesKeras()\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='image.model.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "callbacks = [checkpointer, plot_learning]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the next cell you should train (fit) your network. Try do experiment with different values for the *batch_size* and *epochs* parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model by calling the fit method and supply the necessary\n",
    "# parameters including the validation data\n",
    "hist = model.fit(x_train, y_train, batch_size=100, epochs=50,\n",
    "          validation_data=(x_valid, y_valid), callbacks=callbacks, \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have trained your model you can load the weights and evaluate your model by executing the following cell. You do not have to change any code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights that yielded the best validation accuracy\n",
    "model.load_weights('image.model.weights.best.hdf5')\n",
    "\n",
    "# Evaluate and print test accuracy\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are satisfied with the accuracy of your model you can use it to make the predictions on the test and visualize some samples by executing the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the predictions on the test set\n",
    "y_hat = model.predict(x_test)\n",
    "\n",
    "# Plot a random sample of test images, their predicted labels, and ground truth\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "for i, idx in enumerate(np.random.choice(x_test.shape[0], size=32, replace=False)):\n",
    "    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(x_test[idx]))\n",
    "    pred_idx = np.argmax(y_hat[idx])\n",
    "    true_idx = np.argmax(y_test[idx])\n",
    "    ax.set_title(\"{} ({})\".format(cifar10_labels[pred_idx], cifar10_labels[true_idx]),\n",
    "                 color=(\"green\" if pred_idx == true_idx else \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Congratulations! How did you do with the classification of the images? Did you get an accuracy of .7 and more?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
