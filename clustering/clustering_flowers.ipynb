{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding underlying structures in flowers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The 'hello world'-example of clustering algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we explore a dataset of flowers for underlying structures. We examine the data, try to guess the number of different classes and then apply a k-means clustering algorithm (http://scikit-learn.org/stable/modules/clustering.html#k-means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First explore the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading a flowers dataset\n",
    "iris_data = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the data numerically\n",
    "iris_df = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the data visually with two relevant features\n",
    "plt.scatter(iris_df.iloc[:, 0], iris_df.iloc[:, 2], cmap='viridis')\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('petal length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Estimate the number of classes with the elbow method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Execute the following code cell. Now we try to find the right number of clusters in the dataset by calculating the sum of the squared distances of the points within the clusters. Smaller distances means more compact clusters. After how many clusters the curve (elbow) is flatening out (meaning the distance between the points does not decrease any more)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distances for 1 to 15 clusters\n",
    "squared_distances = []\n",
    "number_of_clusters = range(1,15)\n",
    "for k in number_of_clusters:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(iris_df.iloc[:, [0,2]])\n",
    "    squared_distances.append(km.inertia_)\n",
    "    \n",
    "# Plotting these distances for comparisation\n",
    "plt.plot(number_of_clusters, squared_distances, 'bx-')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('sum of squared distances')\n",
    "plt.title('Elbow Method For Optimal Number of Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Predict the number of classes with k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Initialize a KMeans-Model, set the number of clusters (n_clusters), train the model and make the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and initialize it with the supposed number of clusters\n",
    "# TODO: Initialize a KMeans-Model and set the parameter n_clusters to the number of clusters\n",
    "\n",
    "# TODO: Fit the model and predict the classes (pred)\n",
    "# predicted_classes = model.fit_predict(iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Compare predictions with the real clusters in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare the clustering of the flowers with the target variable in the dataset. How did you do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "ax1.scatter(iris_df.iloc[:, 0], iris_df.iloc[:, 2], c=predicted_classes,cmap='viridis')\n",
    "ax2.scatter(iris_df.iloc[:, 0], iris_df.iloc[:, 2], c=iris_data.target,cmap='viridis')\n",
    "ax1.set_ylabel('petal length')\n",
    "ax1.set_xlabel('sepal length')\n",
    "ax2.set_xlabel('sepal length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Congratulations! You have implemented your first clusting algorithm. Now move on to the next exercise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
